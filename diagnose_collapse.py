#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–∞–ø—Å–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –ø—Ä–æ–±–ª–µ–º —Å –æ–±—É—á–µ–Ω–∏–µ–º
"""

import torch
from torch.utils.data import DataLoader
from pathlib import Path
import numpy as np
import argparse
import json

from eegclip.data import ThingsEEGDataset, create_subject_splits, collate_fn
from eegclip.models import EEGCLIPModel
from eegclip.utils import load_checkpoint, get_device, load_config


def diagnose_collapse(checkpoint_path, data_root="data", n_classes=10, device_str="cuda:0", n_samples=100):
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–∞–ø—Å–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    
    print("=" * 70)
    print("üî¨ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ö–û–õ–õ–ê–ü–°–ê –≠–ú–ë–ï–î–î–ò–ù–ì–û–í")
    print("=" * 70)
    
    device = get_device(device_str)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_dir = Path(checkpoint_path).parent
    config_path = config_dir / "config.json"
    config = load_config(config_path)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    eeg_d_model = config.get('eeg_d_model', 256)
    eeg_layers = config.get('eeg_layers', 4)
    eeg_hidden = config.get('eeg_hidden', 512)
    vision_encoder = config.get('vision_encoder', 'openclip_vit_b32')
    freeze_vision = config.get('freeze_vision', True)
    proj_dim = config.get('proj_dim', 512)
    proj_hidden = config.get('proj_hidden', 1024)
    dropout = config.get('dropout', 0.1)
    temporal_pool = config.get('temporal_pool', 'cls')
    
    # –ú–æ–¥–µ–ª—å
    model = EEGCLIPModel(
        n_channels=17,
        n_timepoints=100,
        eeg_d_model=eeg_d_model,
        eeg_layers=eeg_layers,
        eeg_hidden=eeg_hidden,
        vision_encoder=vision_encoder,
        freeze_vision=freeze_vision,
        proj_dim=proj_dim,
        proj_hidden=proj_hidden,
        dropout=dropout,
        temporal_pool=temporal_pool
    ).to(device)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
    checkpoint = load_checkpoint(checkpoint_path, model, None, None, device)
    model.eval()
    
    # Subject splits
    all_subjects = list(range(1, 11))
    subject_splits = create_subject_splits(
        all_subjects,
        val_ratio=0.1,
        test_ratio=0.1,
        seed=42
    )
    
    # –î–∞—Ç–∞—Å–µ—Ç
    dataset = ThingsEEGDataset(
        data_root=data_root,
        n_classes=n_classes,
        split='val',
        subject_splits=subject_splits,
        eeg_len=100,
        fs=500.0,
        preprocess_eeg=False,
        augment=False
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=32,
        shuffle=False,
        num_workers=0,
        collate_fn=collate_fn
    )
    
    print(f"\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(dataset)}")
    
    # –°–æ–±–∏—Ä–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –º–µ—Ç–∫–∏
    all_eeg_emb = []
    all_img_emb = []
    all_class_idx = []
    all_subject_id = []
    
    with torch.no_grad():
        for batch in dataloader:
            eeg = batch['eeg'].to(device)
            image = batch['image'].to(device)
            class_idx = batch['class_idx']
            subject_id = batch['subject_id']
            
            eeg_emb, img_emb = model(eeg, image)
            
            all_eeg_emb.append(eeg_emb.cpu())
            all_img_emb.append(img_emb.cpu())
            all_class_idx.append(class_idx)
            all_subject_id.append(subject_id)
            
            if len(all_eeg_emb) * 32 >= n_samples:
                break
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
    eeg_emb = torch.cat(all_eeg_emb, dim=0)
    img_emb = torch.cat(all_img_emb, dim=0)
    class_idx = torch.cat(all_class_idx, dim=0)
    subject_id = torch.cat(all_subject_id, dim=0)
    
    n_samples = min(n_samples, len(eeg_emb))
    eeg_emb = eeg_emb[:n_samples]
    img_emb = img_emb[:n_samples]
    class_idx = class_idx[:n_samples]
    subject_id = subject_id[:n_samples]
    
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {n_samples} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–ª–∞–ø—Å–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    print(f"\n{'='*70}")
    print("1Ô∏è‚É£  –ü–†–û–í–ï–†–ö–ê –ö–û–õ–õ–ê–ü–°–ê –≠–ú–ë–ï–î–î–ò–ù–ì–û–í")
    print(f"{'='*70}")
    
    # –°—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
    unique_classes = torch.unique(class_idx)
    print(f"\nüìä –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {unique_classes.tolist()}")
    
    eeg_emb_by_class = {}
    img_emb_by_class = {}
    
    for cls in unique_classes:
        mask = (class_idx == cls)
        eeg_emb_by_class[cls.item()] = eeg_emb[mask]
        img_emb_by_class[cls.item()] = img_emb[mask]
    
    # –°—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    print(f"\nüìä –°—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    for cls in sorted(unique_classes):
        cls_eeg = eeg_emb_by_class[cls.item()]
        cls_img = img_emb_by_class[cls.item()]
        
        mean_eeg = cls_eeg.mean(dim=0)
        mean_img = cls_img.mean(dim=0)
        
        std_eeg = cls_eeg.std(dim=0).mean().item()
        std_img = cls_img.std(dim=0).mean().item()
        
        print(f"   Class {cls.item():2d}: EEG std={std_eeg:.6f}, Image std={std_img:.6f}, "
              f"samples={len(cls_eeg)}")
    
    # 2. –°—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏
    print(f"\n{'='*70}")
    print("2Ô∏è‚É£  –°–•–û–î–°–¢–í–û –ú–ï–ñ–î–£ –ö–õ–ê–°–°–ê–ú–ò")
    print(f"{'='*70}")
    
    # –°—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    mean_eeg_by_class = {}
    mean_img_by_class = {}
    
    for cls in unique_classes:
        mean_eeg_by_class[cls.item()] = eeg_emb_by_class[cls.item()].mean(dim=0, keepdim=True)
        mean_img_by_class[cls.item()] = img_emb_by_class[cls.item()].mean(dim=0, keepdim=True)
    
    # –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏ (EEG)
    print(f"\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏ (EEG —ç–º–±–µ–¥–¥–∏–Ω–≥–∏):")
    n_classes_found = len(unique_classes)
    similarity_matrix_eeg = torch.zeros(n_classes_found, n_classes_found)
    
    for i, cls_i in enumerate(sorted(unique_classes)):
        for j, cls_j in enumerate(sorted(unique_classes)):
            sim = (mean_eeg_by_class[cls_i.item()] @ mean_eeg_by_class[cls_j.item()].T).item()
            similarity_matrix_eeg[i, j] = sim
            if i == j:
                print(f"   Class {cls_i.item():2d} <-> Class {cls_j.item():2d}: {sim:.4f} (self)")
    
    # –î–∏–∞–≥–æ–Ω–∞–ª—å vs –≤–Ω–µ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
    diagonal_eeg = torch.diag(similarity_matrix_eeg)
    off_diagonal_eeg = similarity_matrix_eeg[~torch.eye(n_classes_found, dtype=bool)]
    
    print(f"\n   –î–∏–∞–≥–æ–Ω–∞–ª—å (self-similarity): mean={diagonal_eeg.mean():.4f}, std={diagonal_eeg.std():.4f}")
    print(f"   –í–Ω–µ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ (cross-class): mean={off_diagonal_eeg.mean():.4f}, std={off_diagonal_eeg.std():.4f}")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞: {diagonal_eeg.mean() - off_diagonal_eeg.mean():.4f}")
    
    if diagonal_eeg.mean() - off_diagonal_eeg.mean() < 0.1:
        print(f"   ‚ùå –ü–†–û–ë–õ–ï–ú–ê: –ö–ª–∞—Å—Å—ã –Ω–µ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è!")
    else:
        print(f"   ‚úÖ –ö–ª–∞—Å—Å—ã —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è")
    
    # 3. –°—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–∏
    print(f"\n{'='*70}")
    print("3Ô∏è‚É£  –°–•–û–î–°–¢–í–û –ü–†–ê–í–ò–õ–¨–ù–´–• VS –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–• –ü–ê–†")
    print(f"{'='*70}")
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –Ω–∞—Ö–æ–¥–∏–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–∞—Ä—É
    correct_similarities = []
    incorrect_similarities = []
    
    for i in range(n_samples):
        cls_i = class_idx[i].item()
        eeg_i = eeg_emb[i:i+1]
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–∞—Ä–∞ (–∏–∑ —Ç–æ–≥–æ –∂–µ –∫–ª–∞—Å—Å–∞)
        correct_mask = (class_idx == cls_i)
        correct_img = img_emb[correct_mask]
        if len(correct_img) > 0:
            correct_sim = (eeg_i @ correct_img.T).mean().item()
            correct_similarities.append(correct_sim)
        
        # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã (–∏–∑ –¥—Ä—É–≥–∏—Ö –∫–ª–∞—Å—Å–æ–≤)
        incorrect_mask = (class_idx != cls_i)
        if incorrect_mask.any():
            incorrect_img = img_emb[incorrect_mask]
            incorrect_sim = (eeg_i @ incorrect_img.T).mean().item()
            incorrect_similarities.append(incorrect_sim)
    
    if correct_similarities and incorrect_similarities:
        print(f"\n   –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã: mean={np.mean(correct_similarities):.4f}, std={np.std(correct_similarities):.4f}")
        print(f"   –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã: mean={np.mean(incorrect_similarities):.4f}, std={np.std(incorrect_similarities):.4f}")
        diff = np.mean(correct_similarities) - np.mean(incorrect_similarities)
        print(f"   –†–∞–∑–Ω–∏—Ü–∞: {diff:.4f}")
        
        if diff < 0.05:
            print(f"   ‚ùå –ü–†–û–ë–õ–ï–ú–ê: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã –Ω–µ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è!")
        else:
            print(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã –∏–º–µ—é—Ç –±–æ–ª—å—à–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ")
    
    # 4. –†–∞–∑–±—Ä–æ—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    print(f"\n{'='*70}")
    print("4Ô∏è‚É£  –†–ê–ó–ë–†–û–° –≠–ú–ë–ï–î–î–ò–ù–ì–û–í")
    print(f"{'='*70}")
    
    # –û–±—â–∏–π —Ä–∞–∑–±—Ä–æ—Å
    eeg_std = eeg_emb.std(dim=0).mean().item()
    img_std = img_emb.std(dim=0).mean().item()
    
    print(f"\n   –û–±—â–∏–π —Ä–∞–∑–±—Ä–æ—Å (std –ø–æ –≤—Å–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è–º):")
    print(f"   EEG: {eeg_std:.6f}")
    print(f"   Image: {img_std:.6f}")
    
    if eeg_std < 0.01 or img_std < 0.01:
        print(f"   ‚ùå –ü–†–û–ë–õ–ï–ú–ê: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–æ–ª–ª–∞–ø—Å–∏—Ä–æ–≤–∞–ª–∏ (—Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–±—Ä–æ—Å)!")
    else:
        print(f"   ‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–º–µ—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∞–∑–±—Ä–æ—Å")
    
    # 5. –†–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É —Å—É–±—ä–µ–∫—Ç–∞–º–∏
    print(f"\n{'='*70}")
    print("5Ô∏è‚É£  –†–ê–ó–õ–ò–ß–ò–Ø –ú–ï–ñ–î–£ –°–£–ë–™–ï–ö–¢–ê–ú–ò")
    print(f"{'='*70}")
    
    unique_subjects = torch.unique(subject_id)
    print(f"\nüìä –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—É–±—ä–µ–∫—Ç—ã: {unique_subjects.tolist()}")
    
    # –°—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ —Å—É–±—ä–µ–∫—Ç–∞–º
    eeg_emb_by_subject = {}
    for subj in unique_subjects:
        mask = (subject_id == subj)
        eeg_emb_by_subject[subj.item()] = eeg_emb[mask]
    
    # –°—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É —Å—É–±—ä–µ–∫—Ç–∞–º–∏
    mean_eeg_by_subject = {}
    for subj in unique_subjects:
        mean_eeg_by_subject[subj.item()] = eeg_emb_by_subject[subj.item()].mean(dim=0, keepdim=True)
    
    if len(unique_subjects) > 1:
        subj_list = sorted(unique_subjects)
        subj_similarities = []
        for i, subj_i in enumerate(subj_list):
            for j, subj_j in enumerate(subj_list):
                if i != j:
                    sim = (mean_eeg_by_subject[subj_i.item()] @ mean_eeg_by_subject[subj_j.item()].T).item()
                    subj_similarities.append(sim)
        
        print(f"\n   –°—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É —Å—É–±—ä–µ–∫—Ç–∞–º–∏: mean={np.mean(subj_similarities):.4f}, std={np.std(subj_similarities):.4f}")
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Å—Ö–æ–¥—Å—Ç–≤–æ–º –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏
        if np.mean(subj_similarities) > off_diagonal_eeg.mean():
            print(f"   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –°—É–±—ä–µ–∫—Ç—ã —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è –±–æ–ª—å—à–µ, —á–µ–º –∫–ª–∞—Å—Å—ã!")
            print(f"      –≠—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å, —á—Ç–æ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Ä–∞–∑–ª–∏—á–∞—Ç—å —Å—É–±—ä–µ–∫—Ç–æ–≤, –∞ –Ω–µ –∫–ª–∞—Å—Å—ã.")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –≤—ã–≤–æ–¥
    print(f"\n{'='*70}")
    print("üìä –ò–¢–û–ì–û–í–´–ô –î–ò–ê–ì–ù–û–ó")
    print(f"{'='*70}")
    
    issues = []
    
    if diagonal_eeg.mean() - off_diagonal_eeg.mean() < 0.1:
        issues.append("‚ùå –ö–ª–∞—Å—Å—ã –Ω–µ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö")
    
    if correct_similarities and incorrect_similarities:
        if np.mean(correct_similarities) - np.mean(incorrect_similarities) < 0.05:
            issues.append("‚ùå –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä—ã –Ω–µ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è")
    
    if eeg_std < 0.01 or img_std < 0.01:
        issues.append("‚ùå –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–æ–ª–ª–∞–ø—Å–∏—Ä–æ–≤–∞–ª–∏ (—Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–±—Ä–æ—Å)")
    
    if issues:
        print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã:")
        for issue in issues:
            print(f"   {issue}")
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–∞–∑–ª–∏—á–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏")
        print(f"   2. –£–≤–µ–ª–∏—á—å—Ç–µ learning rate –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É")
        print(f"   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ loss —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ")
        print(f"   4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é —Å –±–æ–ª—å—à–∏–º —Ä–∞–∑–±—Ä–æ—Å–æ–º")
    else:
        print(f"\n‚úÖ –ü—Ä–æ–±–ª–µ–º —Å –∫–æ–ª–ª–∞–ø—Å–æ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        print(f"   –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ –≤ –¥—Ä—É–≥–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ)")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoint_path', type=str, required=True)
    parser.add_argument('--data_root', type=str, default='data')
    parser.add_argument('--n_classes', type=int, default=10)
    parser.add_argument('--device', type=str, default='cuda:0')
    parser.add_argument('--n_samples', type=int, default=100)
    
    args = parser.parse_args()
    
    diagnose_collapse(
        checkpoint_path=args.checkpoint_path,
        data_root=args.data_root,
        n_classes=args.n_classes,
        device_str=args.device,
        n_samples=args.n_samples
    )

